from fastmcp import Client
from openai import AsyncOpenAI

async def send_llm_request_and_display(llm_client, conversation_history, openai_tools):
    """OpenAI APIì— ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ í™”ë©´ì— ì¶œë ¥"""
    response = await llm_client.chat.completions.create(
        model="gpt-4o",
        max_tokens=1000,
        messages=conversation_history,
        tools=openai_tools,
    )
    
    # ëŒ€í™” ê¸°ë¡ì— ì‘ë‹µ ì €ì¥
    conversation_history.append({
        "role": "assistant",
        "content": response.choices[0].message.content,
        "tool_calls": response.choices[0].message.tool_calls
    })
    
    # í…ìŠ¤íŠ¸ ì‘ë‹µ ì¶œë ¥
    if response.choices[0].message.content:
        print("[ğŸ¤– Assistant:]", response.choices[0].message.content)
    
    return response


async def send_tool_request_and_display(response, mcp_client, conversation_history):
    """ë„êµ¬ í˜¸ì¶œì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€"""
    tool_calls = response.choices[0].message.tool_calls
    
    if tool_calls:
        for tool_call in tool_calls:
            print(f"[ğŸ”§ Tool Request] {tool_call.function.name}({tool_call.function.arguments})")
            
            # MCP ì„œë²„ì—ì„œ ë„êµ¬ ì‹¤í–‰
            import json
            args = json.loads(tool_call.function.arguments)
            tool_result = await mcp_client.call_tool(
                tool_call.function.name,
                args
            )
            
            print(f"[âœ… Tool Result] {tool_result}")
            
            # OpenAI API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            conversation_history.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": str(tool_result)
            })

async def main():
    """ì‚¬ìš©ìì™€ OpenAIì˜ ëŒ€í™”í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    llm_client = AsyncOpenAI()
    conversation_history = []
    
    # MCP ì„œë²„ ì—°ê²° ë° ë„êµ¬ ì„¤ì •
    async with Client("http://127.0.0.1:8000/mcp") as mcp_client:
        available_tools = await mcp_client.list_tools()
        openai_tools = [{
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.inputSchema if hasattr(tool, 'inputSchema') else {}
            }
        } for tool in available_tools]
        
        # ëŒ€í™” ì¢…ë£Œ ì‹œ ê¹Œì§€ ë°˜ë³µ
        while True:
            # ì‚¬ìš©ì ì…ë ¥
            user_input = input("[ğŸ‘¤ User]: ")
            conversation_history.append({"role": "user", "content": user_input})
            
            # ë„êµ¬ í˜¸ì¶œì´ í•„ìš” ì—†ì„ ë•Œê¹Œì§€ ë°˜ë³µ
            while True:
                response = await send_llm_request_and_display(
                    llm_client, conversation_history, openai_tools
                )
                
                if response.choices[0].message.tool_calls:
                    await send_tool_request_and_display(
                        response, mcp_client, conversation_history
                    )
                else:
                    break

if __name__ == '__main__':
    import asyncio
    asyncio.run(main())