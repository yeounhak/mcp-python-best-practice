from fastmcp import Client
from anthropic import AsyncAnthropic

async def send_llm_request_and_display(llm_client, conversation_history, anthropic_tools):
    """Claude APIì— ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ í™”ë©´ì— ì¶œë ¥"""
    response = await llm_client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=1000,
        messages=conversation_history,
        tools=anthropic_tools,
    )
    
    # ëŒ€í™” ê¸°ë¡ì— ì‘ë‹µ ì €ì¥
    conversation_history.append({
        "role": "assistant",
        "content": response.content
    })
    
    # í…ìŠ¤íŠ¸ ì‘ë‹µ ì¶œë ¥
    for content_block in response.content:
        if content_block.type == "text":
            print("[ğŸ¤– Assistant:]", content_block.text)
    
    return response


async def send_tool_request_and_display(response, mcp_client, conversation_history):
    """ë„êµ¬ í˜¸ì¶œì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€"""
    tool_results = []
    
    for content_block in response.content:
        if content_block.type == "tool_use":
            print(f"[ğŸ”§ Tool Request] {content_block.name}({content_block.input})")
            
            # MCP ì„œë²„ì—ì„œ ë„êµ¬ ì‹¤í–‰
            tool_result = await mcp_client.call_tool(
                content_block.name,
                content_block.input
            )
            
            print(f"[âœ… Tool Result] {tool_result}")
            
            # Anthropic API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            tool_results.append({
                "type": "tool_result",
                "tool_use_id": content_block.id,
                "content": str(tool_result)
            })
    
    # ë„êµ¬ ê²°ê³¼ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    conversation_history.append({"role": "user", "content": tool_results})

async def main():
    """ì‚¬ìš©ìì™€ Claudeì˜ ëŒ€í™”í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    llm_client = AsyncAnthropic()
    conversation_history = []
    
    # MCP ì„œë²„ ì—°ê²° ë° ë„êµ¬ ì„¤ì •
    async with Client("server.py") as mcp_client:
        available_tools = await mcp_client.list_tools()
        anthropic_tools = [{
            "name": tool.name,
            "description": tool.description,
            "input_schema": tool.inputSchema if hasattr(tool, 'inputSchema') else {}
        } for tool in available_tools]
        
        # ëŒ€í™” ì¢…ë£Œ ì‹œ ê¹Œì§€ ë°˜ë³µ
        while True:
            # ì‚¬ìš©ì ì…ë ¥
            user_input = input("[ğŸ‘¤ User]: ")
            conversation_history.append({"role": "user", "content": user_input})
            
            # ë„êµ¬ í˜¸ì¶œì´ í•„ìš” ì—†ì„ ë•Œê¹Œì§€ ë°˜ë³µ
            while True:
                response = await send_llm_request_and_display(
                    llm_client, conversation_history, anthropic_tools
                )
                
                if response.stop_reason == "tool_use":
                    await send_tool_request_and_display(
                        response, mcp_client, conversation_history
                    )
                else:
                    break

if __name__ == '__main__':
    import asyncio
    asyncio.run(main())