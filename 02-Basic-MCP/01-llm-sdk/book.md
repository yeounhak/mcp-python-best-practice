## ğŸ“‹ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” Anthropic Claudeì™€ OpenAI GPT ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œì˜ ê¸°ë³¸ êµ¬í˜„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‘ ê°€ì§€ ì£¼ìš” LLM(Large Language Model) ì œê³µì—…ì²´ì˜ APIë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¨ë©°, ê°ê°ì˜ í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒìœ¼ë¡œëŠ” Pythonì˜ `asyncio`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¹„ë™ê¸° ì²˜ë¦¬, Anthropicì˜ `anthropic` íŒ¨í‚¤ì§€ì™€ OpenAIì˜ `openai` íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•œ API í†µì‹ , ê·¸ë¦¬ê³  ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¹„ë™ê¸° ì´í„°ë ˆì´í„° íŒ¨í„´ì´ í¬í•¨ë©ë‹ˆë‹¤.

> ğŸ”— **ìƒì„¸ ì½”ë“œ ë° ì˜ˆì œ**: [https://github.com/yeounhak/mcp-python-best-practice/02/01/01-llm-api][github-repo]

[github-repo]: https://github.com/yeounhak/mcp-python-best-practice/02/01/01-llm-api

## ğŸ“ íŒŒì¼ êµ¬ì„±

```
01-llm-api/
â”œâ”€â”€ anthropic.py       # Anthropic Claude API ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° í´ë¼ì´ì–¸íŠ¸
â””â”€â”€ openai.py          # OpenAI GPT API ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° í´ë¼ì´ì–¸íŠ¸
```

### ì£¼ìš” íŒŒì¼ ì„¤ëª…

**anthropic.py**
```python
from anthropic import AsyncAnthropic

client = AsyncAnthropic(
    api_key="sk-ant-..."
)

async def main():
    stream = await client.messages.create(
        model="claude-3-5-sonnet-20241022",
        messages=[{"role": "user", "content": "hi"}],
        max_tokens=1024,
        stream=True
    )
    async for chunk in stream:
        print(chunk)

if __name__ == '__main__':
    import asyncio
    asyncio.run(main())
```
- `AsyncAnthropic` í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ Claude APIì— ë¹„ë™ê¸° ì—°ê²°
- `messages.create()` ë©”ì„œë“œë¡œ Claude 3.5 Sonnet ëª¨ë¸ê³¼ ëŒ€í™” ì„¸ì…˜ ìƒì„±
- `stream=True` ì˜µì…˜ìœ¼ë¡œ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
- `async for` êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬

**openai.py**
```python
from openai import AsyncOpenAI

client = AsyncOpenAI(
    api_key = "sk-..."
)

async def main():
    stream = await client.chat.completions.create(
        model="gpt-5",
        messages=[{"role":"assistant", "content": "hi"}],
        stream=True
    )
    async for chunk in stream:
        print(chunk)

if __name__ == '__main__':
    import asyncio
    asyncio.run(main())
```
- `AsyncOpenAI` í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI APIì— ë¹„ë™ê¸° ì—°ê²°
- `chat.completions.create()` ë©”ì„œë“œë¡œ GPT-5 ëª¨ë¸ê³¼ ì±„íŒ… ì™„ì„± ìš”ì²­ ìƒì„±
- `stream=True` ì„¤ì •ìœ¼ë¡œ í† í°ë³„ ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„
- ë¹„ë™ê¸° ì´í„°ë ˆì´í„°ë¥¼ í†µí•œ ì²­í¬ ë‹¨ìœ„ ì‘ë‹µ ì²˜ë¦¬

## ğŸš€ ì‹¤í–‰

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

**1. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜**
```bash
pip install anthropic openai
```

**2. API í‚¤ ì„¤ì •**
- **Anthropic API í‚¤**: [Anthropic Console](https://console.anthropic.com/)ì—ì„œ API í‚¤ ë°œê¸‰
- **OpenAI API í‚¤**: [OpenAI Platform](https://platform.openai.com/)ì—ì„œ API í‚¤ ë°œê¸‰

**3. API í‚¤ í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)**
```bash
# Anthropic
export ANTHROPIC_API_KEY="your-anthropic-api-key"

# OpenAI  
export OPENAI_API_KEY="your-openai-api-key"
```

### ì‹¤í–‰ ë°©ë²•

**1. Anthropic Claude API ì‹¤í–‰**
```bash
python anthropic.py
```

**2. OpenAI GPT API ì‹¤í–‰**
```bash
python openai.py
```

### ì‹¤í–‰ ê²°ê³¼

**Anthropic Claude ì‹¤í–‰ ê²°ê³¼:**
```bash
$ python anthropic.py
RawMessageStartEvent(type='message_start', message=RawMessage(id='msg_01...', type='message', role='assistant', model='claude-3-5-sonnet-20241022', content=[], max_tokens=1024, stop_reason=None, stop_sequence=None, usage=Usage(input_tokens=8, output_tokens=1)))
RawContentBlockStartEvent(type='content_block_start', index=0, content_block=RawTextBlock(type='text', text=''))
RawContentBlockDeltaEvent(type='content_block_delta', index=0, delta=RawTextDelta(type='text_delta', text='Hello'))
RawContentBlockDeltaEvent(type='content_block_delta', index=0, delta=RawTextDelta(type='text_delta', text='!'))
RawMessageDeltaEvent(type='message_delta', delta=RawMessageDelta(stop_reason='end_turn', stop_sequence=None), usage=RawMessageDeltaUsage(output_tokens=2))
RawMessageStopEvent(type='message_stop')
```

ìœ„ ì¶œë ¥ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì´ë²¤íŠ¸ë“¤:
- **message_start**: ë©”ì‹œì§€ ìƒì„± ì‹œì‘ ë° í† í° ì‚¬ìš©ëŸ‰ ì •ë³´
- **content_block_start**: ì½˜í…ì¸  ë¸”ë¡ ì‹œì‘ 
- **content_block_delta**: ì‹¤ì œ í…ìŠ¤íŠ¸ ì²­í¬ ("Hello", "!")
- **message_delta**: ë©”ì‹œì§€ ì™„ë£Œ ë° ì¤‘ë‹¨ ì´ìœ 
- **message_stop**: ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ

**OpenAI GPT ì‹¤í–‰ ê²°ê³¼:**
```bash
$ python openai.py
ChatCompletionChunk(id='chatcmpl-...', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1640995200, model='gpt-5', object='chat.completion.chunk', system_fingerprint=None, usage=None)
ChatCompletionChunk(id='chatcmpl-...', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1640995200, model='gpt-5', object='chat.completion.chunk', system_fingerprint=None, usage=None)
ChatCompletionChunk(id='chatcmpl-...', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1640995200, model='gpt-5', object='chat.completion.chunk', system_fingerprint=None, usage=None)
ChatCompletionChunk(id='chatcmpl-...', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1640995200, model='gpt-5', object='chat.completion.chunk', system_fingerprint=None, usage=CompletionUsage(completion_tokens=2, prompt_tokens=8, total_tokens=10))
```

OpenAI ì‘ë‹µì—ì„œ ì£¼ëª©í•  ì ë“¤:
- **ChatCompletionChunk**: ê° ì²­í¬ëŠ” ì™„ì „í•œ ì‘ë‹µ ê°ì²´ êµ¬ì¡°ë¥¼ ê°€ì§
- **delta.content**: ì‹¤ì œ ìƒì„±ëœ í…ìŠ¤íŠ¸ ë¶€ë¶„ ("Hello", "!")
- **finish_reason**: ì‘ë‹µ ì™„ë£Œ ì´ìœ  ('stop')
- **usage**: ìµœì¢… ì²­í¬ì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ ì œê³µ

## ğŸ“š ì •ë¦¬

ì´ ì˜ˆì œëŠ” ë‘ ê°€ì§€ ì£¼ìš” LLM ì œê³µì—…ì²´ì¸ Anthropicê³¼ OpenAIì˜ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° APIë¥¼ í™œìš©í•˜ëŠ” ê¸°ë³¸ì ì¸ ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Pythonì˜ `asyncio`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° íŒ¨í„´ì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì„ í•™ìŠµí•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. Anthropicì˜ ê²½ìš° ì´ë²¤íŠ¸ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë°ì„ í†µí•´ ë©”ì‹œì§€ ì‹œì‘ë¶€í„° ì¢…ë£Œê¹Œì§€ì˜ ì„¸ë¶€ì ì¸ ìƒíƒœë¥¼ ì¶”ì í•  ìˆ˜ ìˆìœ¼ë©°, OpenAIëŠ” ì²­í¬ ë‹¨ìœ„ë¡œ êµ¬ì¡°í™”ëœ ì‘ë‹µì„ ì œê³µí•˜ì—¬ ê°ê°ì˜ ì¥ë‹¨ì ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ API ëª¨ë‘ `stream=True` ì˜µì…˜ê³¼ `async for` êµ¬ë¬¸ì„ í†µí•´ ì¼ê´€ëœ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° íŒ¨í„´ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ëŠ” ì‹¤ì‹œê°„ ì‘ë‹µ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê¸°ì´ˆë¥¼ ë§ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.